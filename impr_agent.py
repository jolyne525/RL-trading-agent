import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import yfinance as yf
import time

# é¡µé¢é…ç½®
st.set_page_config(page_title="ç®—æ³•äº¤æ˜“æ™ºèƒ½ä½“", page_icon="ğŸ¤–", layout="wide")

# è‚¡ç¥¨å¸‚åœºç¯å¢ƒ MDP å®šä¹‰
class StockEnvironment:
    """
    æ¨¡æ‹Ÿè‚¡ç¥¨å¸‚åœºç¯å¢ƒ (MDP)ã€‚
    çŠ¶æ€: [ä»Šæ—¥æ”¶ç›Šç‡, æŒä»“æ ‡å¿—, åç½®é¡¹]
    åŠ¨ä½œ: 0=æŒæœ‰, 1=ä¹°å…¥, 2=å–å‡º
    å¥–åŠ±: å‡€å€¼å˜åŠ¨ + äº¤æ˜“æˆæœ¬æƒ©ç½š (æ¯æ¬¡äº¤æ˜“ -0.05)
    """
    def __init__(self, data, initial_balance=10000):
        # ç¡®ä¿ç´¢å¼•è¿ç»­ï¼ŒåŒ…å« Date åˆ—ç”¨äºè®°å½•
        self.data = data.reset_index(drop=True)
        self.initial_balance = initial_balance
        self.reset()
        
    def reset(self):
        self.step_index = 0
        self.balance = self.initial_balance
        self.shares = 0
        self.net_worth = self.initial_balance
        self.trade_volume = 0.0  # é‡ç½®ç´¯è®¡äº¤æ˜“é¢
        self.history = []
        return self._get_state()
        
    def _get_state(self):
        # è¿”å›å½“å‰çŠ¶æ€å‘é‡: [å½“æ—¥ä»·æ ¼å˜åŠ¨ç‡, æ˜¯å¦æŒä»“, åç½®é¡¹]
        if self.step_index >= len(self.data):
            return np.zeros(3)
        price = self.data.iloc[self.step_index]['Close']
        if self.step_index > 0:
            prev_price = self.data.iloc[self.step_index - 1]['Close']
            pct_change = (price - prev_price) / prev_price
        else:
            pct_change = 0.0
        has_position = 1 if self.shares > 0 else 0
        return np.array([pct_change, has_position, 1.0])

    def step(self, action):
        # æ‰§è¡ŒåŠ¨ä½œå¹¶æ¨è¿›ç¯å¢ƒä¸€ä¸ªæ—¶é—´æ­¥
        current_price = self.data.iloc[self.step_index]['Close']
        reward = 0.0
        prev_net_worth = self.net_worth
        # æ‰§è¡Œä¹°å…¥åŠ¨ä½œ
        if action == 1:
            if self.balance >= current_price:
                self.shares += 1
                self.balance -= current_price
                reward -= 0.05  # äº¤æ˜“æˆæœ¬æƒ©ç½š
                # ç´¯è®¡äº¤æ˜“é¢
                self.trade_volume += current_price
        # æ‰§è¡Œå–å‡ºåŠ¨ä½œ
        elif action == 2:
            if self.shares > 0:
                self.shares -= 1
                self.balance += current_price
                reward -= 0.05  # äº¤æ˜“æˆæœ¬æƒ©ç½š
                self.trade_volume += current_price
        # è®¡ç®—æ–°çš„å‡€å€¼ï¼ˆèµ„äº§å‡€å€¼ = ç°é‡‘ + æŒä»“*ç°ä»·ï¼‰
        self.net_worth = self.balance + self.shares * current_price
        # å¥–åŠ±ä¸ºå‡€å€¼çš„å¢å‡é‡ï¼ˆåŒ…å«æœªå®ç°ç›ˆäºï¼‰
        reward += (self.net_worth - prev_net_worth)
        # è®°å½•å½“å‰æ—¶é—´æ­¥ä¿¡æ¯
        self.history.append({
            'step': self.step_index,
            'date': self.data.iloc[self.step_index]['Date'],
            'price': current_price,
            'action': action,
            'net_worth': self.net_worth
        })
        # æ—¶é—´æ­¥è¿›
        self.step_index += 1
        # åˆ¤æ–­æ˜¯å¦åˆ°è¾¾æ•°æ®æœ«å°¾ï¼ˆæœ€åä¸€ä¸ªæ•°æ®ç‚¹ç”¨äºè®¡ç®—å‡€å€¼å˜åŒ–ï¼Œä¸æ‰§è¡ŒåŠ¨ä½œï¼‰
        done = self.step_index >= len(self.data) - 1
        next_state = self._get_state()
        return next_state, reward, done

# æ·±åº¦ Q ç½‘ç»œæ™ºèƒ½ä½“å®šä¹‰
class DQNAgent:
    """
    æ·±åº¦Qç½‘ç»œä»£ç† (DQN)ï¼Œä½¿ç”¨ä¸€å±‚éšè—å±‚è¿›è¡Œè¿‘ä¼¼ï¼Œå…·å¤‡ Îµ-è´ªå¿ƒç­–ç•¥ã€‚
    """
    def __init__(self, state_size, action_size, hidden_size=16):
        self.state_size = state_size
        self.action_size = action_size
        self.hidden_size = hidden_size
        # åˆå§‹åŒ–ç½‘ç»œå‚æ•°ï¼ˆæƒé‡åœ¨ -0.5~0.5 ä¹‹é—´å‡åŒ€åˆ†å¸ƒï¼‰
        self.w1 = np.random.rand(self.state_size, self.hidden_size) - 0.5
        self.b1 = np.zeros(self.hidden_size)
        self.w2 = np.random.rand(self.hidden_size, self.action_size) - 0.5
        self.b2 = np.zeros(self.action_size)
        # å­¦ä¹ ç‡å’ŒæŠ˜æ‰£å› å­ã€æ¢ç´¢ç‡å‚æ•°
        self.learning_rate = 0.1
        self.gamma = 0.95
        self.epsilon = 1.0
        self.epsilon_decay = 0.95
        self.epsilon_min = 0.01

    def act(self, state):
        # Îµ-è´ªå¿ƒé€‰æ‹©åŠ¨ä½œ
        if np.random.rand() <= self.epsilon:
            return np.random.randint(self.action_size)
        # å‰å‘ä¼ æ’­è®¡ç®— Q(s, a) å¹¶é€‰æ‹©ä½¿ Q æœ€å¤§çš„åŠ¨ä½œ
        z1 = np.dot(state, self.w1) + self.b1
        hidden = np.where(z1 > 0, z1, 0)  # ReLU æ¿€æ´»
        q_values = np.dot(hidden, self.w2) + self.b2
        return int(np.argmax(q_values))

    def learn(self, state, action, reward, next_state):
        # è®¡ç®—å½“å‰çŠ¶æ€å’Œä¸‹ä¸€çŠ¶æ€çš„ Q å€¼
        z1 = np.dot(state, self.w1) + self.b1
        hidden = np.where(z1 > 0, z1, 0)
        q_values = np.dot(hidden, self.w2) + self.b2
        z1_next = np.dot(next_state, self.w1) + self.b1
        hidden_next = np.where(z1_next > 0, z1_next, 0)
        q_next = np.dot(hidden_next, self.w2) + self.b2
        # ç›®æ ‡ Q å€¼å’Œ TD è¯¯å·®
        target = reward + self.gamma * np.max(q_next)
        error = target - q_values[action]
        # æ›´æ–°è¾“å‡ºå±‚ (é’ˆå¯¹æ‰§è¡Œçš„ action)
        self.w2[:, action] += self.learning_rate * error * hidden
        self.b2[action]     += self.learning_rate * error
        # æ›´æ–°éšè—å±‚
        hidden_grad = error * self.w2[:, action]
        hidden_grad = hidden_grad * (hidden > 0)  # ä»…æ›´æ–°æ¿€æ´»çš„éšè—å•å…ƒ
        self.w1 += self.learning_rate * np.outer(state, hidden_grad)
        self.b1 += self.learning_rate * hidden_grad
        # è¡°å‡æ¢ç´¢ç‡ Îµ
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

@st.cache_data
def get_real_stock_data(ticker="NVDA", start="2021-01-01", end="2021-06-01"):
    """
    è·å–çœŸå®è‚¡ç¥¨æ”¶ç›˜ä»·æ•°æ®ï¼ˆé»˜è®¤NVDA 2021å¹´ä¸ŠåŠå¹´ï¼‰ã€‚
    """
    try:
        df = yf.download(ticker, start=start, end=end, progress=False)
        if df.empty:
            return pd.DataFrame()
        df = df.reset_index()
        # å¦‚æœæœ‰å¤æƒæ”¶ç›˜ä»·ï¼Œåˆ™ç”¨å®ƒä½œä¸ºæ”¶ç›˜ä»·
        if 'Adj Close' in df.columns:
            df['Close'] = df['Adj Close']
        # åªä¿ç•™æ—¥æœŸå’Œæ”¶ç›˜ä»·åˆ—
        return df[['Date', 'Close']]
    except Exception as e:
        st.error(f"æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        return pd.DataFrame()

# åº”ç”¨æ ‡é¢˜å’Œè¯´æ˜
st.title("Reinforcement Learning Quantitative Trader")
st.markdown("""
* **æ ¸å¿ƒæŠ€æœ¯:** æ·±åº¦ Q ç½‘ç»œ (DQN) å¼ºåŒ–å­¦ä¹ , é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (MDP), é‡åŒ–åˆ†æ  
* **æ•°æ®æº:** Yahoo Finance å†å²å¸‚åœºæ•°æ® (2021 å¹´)
""")
st.divider()

# å¸ƒå±€ä¸¤åˆ—ï¼šå·¦ä¾§å‚æ•°ï¼Œå³ä¾§è¾“å‡º
col1, col2 = st.columns([1, 3])
with col1:
    st.subheader("âš™ï¸ å‚æ•°è®¾ç½®")
    ticker_input = st.text_input("è‚¡ç¥¨ä»£ç ï¼ˆå¯è¾“å…¥å¤šä¸ªï¼Œç”¨é€—å·åˆ†éš”ï¼‰", "NVDA")
    episodes = st.slider("è®­ç»ƒè½®æ•°", 10, 100, 50)
    train_btn = st.button("ğŸš€ å¼€å§‹è®­ç»ƒ & å›æµ‹", type="primary")
    st.info("""
    **è®­ç»ƒåŸç†:**  
    æ™ºèƒ½ä½“åœ¨å†å²æ•°æ®ä¸Šé€šè¿‡ Trial-and-Error è¿›è¡Œå­¦ä¹ ï¼Œå°è¯•åœ¨ä¸åŒæ³¢åŠ¨æƒ…å†µä¸‹é‡‡å–ä¹°/å–æ“ä½œï¼Œä»¥æœ€å¤§åŒ–é•¿æœŸå‡€å€¼å¢é•¿ï¼ˆè€ƒè™‘äº¤æ˜“æˆæœ¬ï¼‰ã€‚è®­ç»ƒå®Œæˆåï¼Œåœ¨æœªæ¥æ•°æ®ä¸Šå›æµ‹ç­–ç•¥è¡¨ç°ã€‚
    """)

# å¦‚æœ session_state ä¸­æ²¡æœ‰å¸‚åœºæ•°æ®ï¼Œåˆ™è·å–é»˜è®¤ NVDA æ•°æ®ç”¨äºåˆå§‹é¢„è§ˆ
if 'market_data' not in st.session_state:
    st.session_state.market_data = get_real_stock_data()
df_preview = st.session_state.market_data

# ä¸»é€»è¾‘ï¼šç‚¹å‡»è®­ç»ƒæŒ‰é’®åæ‰§è¡Œ
if train_btn:
    with col2:
        # å¤„ç†è¾“å…¥çš„è‚¡ç¥¨åˆ—è¡¨
        tickers = [t.strip() for t in ticker_input.split(',') if t.strip()]
        results = []
        total_iterations = len(tickers) * episodes
        current_iter = 0
        progress_bar = st.progress(0.0)
        status_text = st.empty()
        start_time = time.time()
        # éå†æ¯ä¸ªè‚¡ç¥¨ä¾æ¬¡è®­ç»ƒå’Œæµ‹è¯•
        for idx, ticker in enumerate(tickers, start=1):
            df = get_real_stock_data(ticker)
            if df.empty:
                st.error(f"æ— æ³•è·å– {ticker} çš„æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»£ç æ˜¯å¦æ­£ç¡®ã€‚")
                st.stop()
            # æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† (70%/30%)
            train_size = int(len(df) * 0.7)
            train_df = df.iloc[:train_size]
            test_df = df.iloc[train_size:]
            env_train = StockEnvironment(train_df)
            agent = DQNAgent(state_size=3, action_size=3)
            # ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¬¬ä¸€è½®ã€ä¸­é—´è½®æ¬¡ã€æœ€åä¸€è½®è®°å½•
            first_episode_history = None
            mid_episode_history = None
            final_episode_history = None
            mid_index = episodes // 2  # ä¸­é—´è½®æ¬¡ç´¢å¼•
            # è®­ç»ƒæ™ºèƒ½ä½“
            for e in range(episodes):
                state = env_train.reset()
                done = False
                total_reward = 0.0
                while not done:
                    action = agent.act(state)
                    next_state, reward, done = env_train.step(action)
                    agent.learn(state, action, reward, next_state)
                    state = next_state
                    total_reward += reward
                # è®°å½•ç¬¬1è½®ã€ä¸­é—´è½®ã€æœ€åä¸€è½®çš„äº¤æ˜“å†å²
                if e == 0:
                    first_episode_history = env_train.history.copy()
                if e == mid_index:
                    mid_episode_history = env_train.history.copy()
                if e == episodes - 1:
                    final_episode_history = env_train.history.copy()
                # æ›´æ–°å…¨å±€è®­ç»ƒè¿›åº¦
                current_iter += 1
                progress = current_iter / total_iterations
                progress_bar.progress(progress)
                if len(tickers) > 1:
                    status_text.code(f"{ticker.upper()} - Episode {e+1}/{episodes} | Total Reward: {total_reward:.2f} | Epsilon: {agent.epsilon:.2f}")
                else:
                    status_text.code(f"Episode {e+1}/{episodes} | Total Reward: {total_reward:.2f} | Epsilon: {agent.epsilon:.2f}")
            # åœ¨æµ‹è¯•é›†ä¸Šå›æµ‹ç­–ç•¥
            env_test = StockEnvironment(test_df)
            state = env_test.reset()
            agent.epsilon = 0.0  # æµ‹è¯•æ—¶å…³é—­æ¢ç´¢
            done = False
            while not done:
                action = agent.act(state)
                next_state, reward, done = env_test.step(action)
                state = next_state
            # æ”¶é›†æµ‹è¯•ç»“æœå’ŒæŒ‡æ ‡
            history_df = pd.DataFrame(env_test.history)
            initial_balance = env_test.initial_balance
            initial_price = history_df.iloc[0]['price']
            history_df['benchmark_nav'] = initial_balance * (history_df['price'] / initial_price)
            strategy_return = (history_df.iloc[-1]['net_worth'] - initial_balance) / initial_balance
            benchmark_return = (history_df.iloc[-1]['benchmark_nav'] - initial_balance) / initial_balance
            alpha = strategy_return - benchmark_return
            history_df['pct_change'] = history_df['net_worth'].pct_change().fillna(0)
            risk_free_rate = 0.02
            daily_rf = risk_free_rate / 252
            excess_returns = history_df['pct_change'] - daily_rf
            sharpe_ratio = 0.0
            if np.std(excess_returns) != 0:
                sharpe_ratio = np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)
            cum_max = history_df['net_worth'].cummax()
            max_drawdown = (1 - history_df['net_worth'] / cum_max).max()
            turnover = env_test.trade_volume / initial_balance
            results.append({
                'ticker': ticker.upper(),
                'history_df': history_df,
                'metrics': {
                    'Return (%)': f"{strategy_return*100:.1f}%",
                    'Sharpe Ratio': f"{sharpe_ratio:.2f}",
                    'Max Drawdown (%)': f"{max_drawdown*100:.1f}%",
                    'Turnover (%)': f"{turnover*100:.1f}%",
                    'Alpha (%)': f"{alpha*100:.1f}%"
                },
                'first_ep': first_episode_history,
                'mid_ep': mid_episode_history,
                'last_ep': final_episode_history
            })
        # æ¸…é™¤è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
        progress_bar.empty()
        status_text.empty()
        st.success(f"è®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶ {time.time() - start_time:.2f} ç§’")
        # å¯è§†åŒ–ç»“æœ
        # å¤šè‚¡ç¥¨å¯¹æ¯”æ¨¡å¼
        if len(tickers) > 1:
            st.subheader("1. ç­–ç•¥ç»©æ•ˆå¯¹æ¯”ï¼ˆå¤šè‚¡ç¥¨ï¼‰")
            fig = go.Figure()
            color_palette = px.colors.qualitative.Plotly
            for i, res in enumerate(results):
                ticker = res['ticker']
                history_df = res['history_df']
                color = color_palette[i % len(color_palette)]
                # ç­–ç•¥å‡€å€¼æ›²çº¿
                fig.add_trace(go.Scatter(
                    x=history_df['date'], y=history_df['net_worth'],
                    mode='lines', name=f"{ticker} RLç­–ç•¥", 
                    line=dict(color=color, width=3)
                ))
                # åŸºå‡†å‡€å€¼æ›²çº¿
                fig.add_trace(go.Scatter(
                    x=history_df['date'], y=history_df['benchmark_nav'],
                    mode='lines', name=f"{ticker} åŸºå‡†", 
                    line=dict(color=color, width=2, dash='dash')
                ))
            fig.update_layout(yaxis_title="Net Worth ($)")
            st.plotly_chart(fig, use_container_width=True)
            # ä¸åŒè‚¡ç¥¨çš„é‡åŒ–æŒ‡æ ‡è¡¨æ ¼
            st.subheader("2. å…³é”®é‡åŒ–æŒ‡æ ‡å¯¹æ¯”")
            metrics_rows = []
            for res in results:
                row = {'Ticker': res['ticker']}
                row.update(res['metrics'])
                metrics_rows.append(row)
            metrics_df = pd.DataFrame(metrics_rows).set_index('Ticker')
            st.table(metrics_df)
        # å•è‚¡ç¥¨æ¨¡å¼
        else:
            res = results[0]
            ticker = res['ticker']
            history_df = res['history_df']
            # äº¤æ˜“å†³ç­–å¯è§†åŒ–å›¾ (ä¹°å–ç‚¹)
            st.subheader("1. äº¤æ˜“å†³ç­–å¯è§†åŒ–")
            fig_price = go.Figure()
            fig_price.add_trace(go.Scatter(
                x=history_df['date'], y=history_df['price'],
                mode='lines', name=f"{ticker} æ”¶ç›˜ä»·", line=dict(color='gray', width=1)
            ))
            buy_signals = history_df[history_df['action'] == 1]
            sell_signals = history_df[history_df['action'] == 2]
            fig_price.add_trace(go.Scatter(
                x=buy_signals['date'], y=buy_signals['price'],
                mode='markers', name='ä¹°å…¥ä¿¡å·',
                marker=dict(symbol='triangle-up', color='green', size=10)
            ))
            fig_price.add_trace(go.Scatter(
                x=sell_signals['date'], y=sell_signals['price'],
                mode='markers', name='å–å‡ºä¿¡å·',
                marker=dict(symbol='triangle-down', color='red', size=10)
            ))
            st.plotly_chart(fig_price, use_container_width=True)
            # ç­–ç•¥å‡€å€¼ vs åŸºå‡† å‡€å€¼æ›²çº¿
            st.subheader("2. ç­–ç•¥ç»©æ•ˆå¯¹æ¯”")
            fig_nav = go.Figure()
            fig_nav.add_trace(go.Scatter(
                x=history_df['date'], y=history_df['net_worth'],
                mode='lines', name='RL ç­–ç•¥å‡€å€¼', line=dict(color='#636EFA', width=3)
            ))
            fig_nav.add_trace(go.Scatter(
                x=history_df['date'], y=history_df['benchmark_nav'],
                mode='lines', name='ä¹°å…¥æŒæœ‰å‡€å€¼', line=dict(color='gray', dash='dash')
            ))
            fig_nav.update_layout(yaxis_title="Net Worth ($)")
            st.plotly_chart(fig_nav, use_container_width=True)
            # å…³é”®é‡åŒ–æŒ‡æ ‡ (å•è‚¡ç¥¨)
            st.subheader("3. å…³é”®é‡åŒ–æŒ‡æ ‡")
            strategy_return = float(res['metrics']['Return (%)'].strip('%'))
            benchmark_return = (history_df.iloc[-1]['benchmark_nav'] - initial_balance) / initial_balance
            k1, k2, k3 = st.columns(3)
            k1.metric("ç´¯è®¡æ”¶ç›Š", res['metrics']['Return (%)'], delta=f"åŸºå‡† {benchmark_return*100:.1f}%")
            k2.metric("å¤æ™®æ¯”ç‡", f"{float(res['metrics']['Sharpe Ratio']):.2f}", help=">1.0 é€šå¸¸è¢«è®¤ä¸ºæ˜¯ä¼˜ç§€çš„")
            k3.metric("Alpha (è¶…é¢æ”¶ç›Š)", res['metrics']['Alpha (%)'], delta="CV Key Metric")
            k4, k5 = st.columns(2)
            k4.metric("æœ€å¤§å›æ’¤", res['metrics']['Max Drawdown (%)'])
            k5.metric("å‘¨è½¬ç‡", res['metrics']['Turnover (%)'])
            # å­¦ä¹ è¿‡ç¨‹æƒç›Šæ›²çº¿å¯¹æ¯”å›¾
            st.subheader("4. è®­ç»ƒè½®æ¬¡æƒç›Šæ›²çº¿å¯¹æ¯”")
            first_ep = pd.DataFrame(res['first_ep'])
            mid_ep = pd.DataFrame(res['mid_ep']) if res['mid_ep'] is not None else None
            last_ep = pd.DataFrame(res['last_ep'])
            fig_learning = go.Figure()
            fig_learning.add_trace(go.Scatter(
                x=first_ep['date'], y=first_ep['net_worth'],
                mode='lines', name='ç¬¬1è½®',
                line=dict(color='gray', dash='dash')
            ))
            if mid_ep is not None:
                fig_learning.add_trace(go.Scatter(
                    x=mid_ep['date'], y=mid_ep['net_worth'],
                    mode='lines', name=f"ç¬¬{mid_index+1}è½®",
                    line=dict(color='orange', dash='dashdot')
                ))
            fig_learning.add_trace(go.Scatter(
                x=last_ep['date'], y=last_ep['net_worth'],
                mode='lines', name=f"ç¬¬{episodes}è½®",
                line=dict(color='#636EFA', width=3)
            ))
            fig_learning.update_layout(yaxis_title="Net Worth ($)")
            st.plotly_chart(fig_learning, use_container_width=True)
else:
    # åˆæ¬¡åŠ è½½æˆ–æœªç‚¹å‡»å¼€å§‹æ—¶ï¼Œæ˜¾ç¤ºé¢„è§ˆå›¾
    with col2:
        st.info("ğŸ‘ˆ è¯·è®¾ç½®å‚æ•°å¹¶ç‚¹å‡» 'å¼€å§‹è®­ç»ƒ & å›æµ‹' æŒ‰é’®")
        if df_preview is not None and not df_preview.empty:
            fig_preview = px.line(df_preview, x='Date', y='Close', title=f"{df_preview.iloc[0]['Date'].strftime('%Y-%m-%d')} ~ {df_preview.iloc[-1]['Date'].strftime('%Y-%m-%d')} æ”¶ç›˜ä»·")
            st.plotly_chart(fig_preview, use_container_width=True)
        else:
            st.error("æ²¡æœ‰é¢„è§ˆæ•°æ®å¯æ˜¾ç¤ºï¼Œè¯·æ£€æŸ¥æ•°æ®æºã€‚")
